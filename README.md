# **üè¶ Sistema de Distribui√ß√£o Inteligente de Carteira Banc√°ria**  

[![Licen√ßa MIT](https://img.shields.io/badge/Licen√ßa-MIT-blue.svg)](https://opensource.org/licenses/MIT)  
[![Python 3.8+](https://img.shields.io/badge/Python-3.8+-blue?logo=python)](https://www.python.org/)  
[![PySpark 3.3+](https://img.shields.io/badge/PySpark-3.3+-E25A1C?logo=apachespark)](https://spark.apache.org/)  
[![Databricks](https://img.shields.io/badge/Databricks-Runtime_10.4+-FF3621?logo=databricks)](https://databricks.com/)  

---

## **üìå Vis√£o Geral**  
Solu√ß√£o **PySpark** para distribui√ß√£o **automatizada e balanceada** de clientes para gerentes banc√°rios, garantindo:  

‚úî **Aloca√ß√£o geogr√°fica inteligente** (`localpara`)  
‚úî **Balanceamento justo** (m√©todo rand√¥mico)  
‚úî **Valida√ß√£o rigorosa** (dados completos e sem duplicidades)  
‚úî **Logging detalhado** para rastreabilidade  

---

## **üìä Fluxo do Sistema**  

```mermaid
graph TD
    A[Base de Clientes] --> B{Processamento Spark}
    C[Base de Gerentes] --> B
    B --> D[Join por localpara]
    D --> E[Distribui√ß√£o Rand√¥mica]
    E --> F[Valida√ß√£o de Qualidade]
    F --> G[(Tabela Final)]
    style A fill:#4CAF50,stroke:#388E3C
    style C fill:#2196F3,stroke:#0D47A1
    style G fill:#FF9800,stroke:#F57C00
```

---

## **‚öôÔ∏è Arquitetura T√©cnica**  

```mermaid
flowchart TB
    subgraph "Spark Cluster"
    Driver --> Executor1
    Driver --> Executor2
    Driver --> ExecutorN
    end
    Executor1 --> HDFS[(HDFS)]
    Executor2 --> HDFS
    ExecutorN --> HDFS
```

---

## **üìà M√©tricas-Chave**  

```mermaid
pie
    title Tempo por Etapa (Exemplo)
    "Carga de Dados" : 25
    "Join e Filtros" : 30
    "Distribui√ß√£o" : 35
    "Valida√ß√£o" : 10
```

---

## **üí° Como Funciona?**  

### **1. Carga de Dados**  
```python
clientes_df = spark.table("schema.tb_clientes").filter(F.col("localpara").isNotNull())
gerentes_df = spark.table("schema.tb_clientes").filter(F.col("localpara").isNotNull())
```

### **2. Algoritmo de Distribui√ß√£o**  
```python
window = Window.partitionBy("nr_pess").orderBy(F.rand())
distribuicao = (clientes_df.join(gerentes_df, "localpara")
                .withColumn("rank", F.row_number().over(window))
                .filter(F.col("rank") == 1))
```

### **3. Valida√ß√£o**  
```python
duplicados = df.groupBy("nr_pess").agg(F.count("*").alias("qtd")).filter(F.col("qtd") > 1)
if duplicados.count() > 0:
    raise Exception("Clientes duplicados!")
```

---

## **üöÄ Resultados Garantidos**  

| **M√©trica**               | **Resultado**                |
|---------------------------|------------------------------|
| **Clientes Distribu√≠dos** | 100% sem duplicidades        |
| **Balanceamento**         | Aleatoriedade controlada     |
| **Logging**              | Rastreio completo por etapa  |
| **Performance**          | Otimizado para 600 parti√ß√µes |

---

## **üõ†Ô∏è Como Executar?**  

1. **Configura√ß√£o**:  
   ```python
   @dataclass
   class Config:
       LIMITE_CLIENTES: int = 1473  # Ajuste conforme necessidade
   ```

2. **Submiss√£o**:  
   ```bash
   spark-submit --master yarn --deploy-mode cluster main.py
   ```

3. **Monitoramento**:  
   ```python
   logger.info(f"Clientes processados: {df.count()}")
   ```

---

## **üìå Exemplo de Sa√≠da**  

```mermaid
gantt
    title Tempo de Execu√ß√£o (Exemplo)
    dateFormat  HH:mm:ss
    section Processamento
    Carga de Dados      :a1, 00:00:00, 00:02:30
    Join e Distribui√ß√£o :a2, after a1, 00:05:00
    Valida√ß√£o           :a3, after a2, 00:01:00
```

---

## **üîß Stack Utilizada**  

| **Tecnologia**       | **Uso**                          |
|-----------------------|----------------------------------|
| PySpark              | Processamento distribu√≠do        |
| Databricks           | Ambiente de execu√ß√£o             |
| Python               | L√≥gica de neg√≥cio               |
| Git                  | Controle de vers√£o              |

---

 
[![LinkedIn](https://img.shields.io/badge/Felipe_Bonatti-LinkedIn-blue?logo=linkedin)](https://www.linkedin.com/in/felipebsdelima)  


---

> **Nota**: Projeto em conformidade com **LGPD**. Dados sens√≠veis foram anonimizados.  

